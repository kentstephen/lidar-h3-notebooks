{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Rich H3 Schema — Classification + Elevation Visualization\n",
    "\n",
    "This notebook reads pre-computed H3 hex data from `duckdb/san_fran_ept_lpc.ddb` \n",
    "(built by the 50-min concurrent PDAL pipeline in `new_schema_for_ept_duckdb_h3.ipynb`) \n",
    "and produces classification-colored 3D hex maps.\n",
    "\n",
    "**Tables in the .ddb:**\n",
    "- `raw_hex_batches` — per-tile H3 aggregates (15 cols, ~3M rows) — the expensive data\n",
    "- `san_fran_rich_res_13` — final reduced table (re-runnable in seconds from raw_hex_batches)\n",
    "\n",
    "**NOTE**: Use Jupyter Lab (not VS Code) for lonboard rendering with this much data (~3M hex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DB_PATH = 'duckdb/san_fran_ept_lpc.ddb'\n",
    "DDB_TABLE = 'san_fran_rich_res_13'\n",
    "H3_RES = 13\n",
    "MIN_CNT = 10  # filter sparse hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import numpy as np\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "duckdb.sql(\"INSTALL h3 FROM community\")\n",
    "duckdb.sql(\"INSTALL spatial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduction-header",
   "metadata": {},
   "source": "## Load final table (or re-reduce from raw batches)\n\nIf `san_fran_rich_res_13` already exists, just prints summary stats.\nSet `FORCE_REBUILD = True` to re-run the reduction from `raw_hex_batches` (~5 sec).\n\n**Geometric structure detection**: CA_SanFrancisco_1_B23 has NO building (class 6) or \nvegetation (class 3/4/5) classification — 69% is class 1 (Unclassified), 30% class 2 (Ground). \nSo `building_cnt` and `veg_cnt` from the worker are always 0. Instead, we derive structure class \nfrom **height above ground** (avg_z - ground_z > 3m) and split building vs vegetation using \n**multi-return ratio** (vegetation has high multi-return ~0.63 from laser penetrating canopy; \nbuildings reflect cleanly ~0.14)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduction",
   "metadata": {},
   "outputs": [],
   "source": "FORCE_REBUILD = False\n\ncon = duckdb.connect(DB_PATH)\ncon.sql(\"LOAD h3\")\n\ntable_exists = con.sql(f\"\"\"\n    SELECT COUNT(*) AS n FROM information_schema.tables\n    WHERE table_name = '{DDB_TABLE}'\n\"\"\").fetchone()[0] > 0\n\nif not table_exists or FORCE_REBUILD:\n    print(\"Rebuilding from raw_hex_batches...\" if table_exists else \"Table missing, building...\")\n    con.sql(f\"\"\"\n        CREATE OR REPLACE TABLE {DDB_TABLE} AS\n        WITH base AS (\n            SELECT \n                hex,\n                h3_cell_to_lat(hex) AS lat,\n                h3_cell_to_lng(hex) AS lng,\n                SUM(avg_z * cnt) / SUM(cnt) AS avg_z,\n                MIN(min_z) AS min_z,\n                MAX(max_z) AS max_z,\n                MAX(max_z) - MIN(min_z) AS z_range,\n                SUM(cnt) AS cnt,\n                SUM(ground_z * ground_cnt) / NULLIF(SUM(ground_cnt), 0) AS ground_z,\n                SUM(ground_cnt) AS ground_cnt,\n                (SUM(avg_z * cnt) / SUM(cnt)) - (SUM(ground_z * ground_cnt) / NULLIF(SUM(ground_cnt), 0)) AS structure_height,\n                SUM(building_cnt) AS building_cnt,\n                SUM(bridge_cnt) AS bridge_cnt,\n                SUM(veg_cnt) AS veg_cnt,\n                SUM(water_cnt) AS water_cnt,\n                SUM(avg_intensity * cnt) / SUM(cnt) AS avg_intensity,\n                SUM(multi_return_ratio * cnt) / SUM(cnt) AS multi_return_ratio,\n                SUM(canopy_height * veg_cnt) / NULLIF(SUM(veg_cnt), 0) AS canopy_height\n            FROM raw_hex_batches\n            GROUP BY 1\n        )\n        SELECT *,\n            CASE\n                WHEN bridge_cnt::DOUBLE / cnt > 0.1 THEN 'bridge'\n                WHEN water_cnt::DOUBLE / cnt > 0.3 THEN 'water'\n                WHEN ground_z IS NOT NULL\n                     AND (avg_z - ground_z) > 3.0\n                     AND (avg_z - ground_z) <= 40.0\n                     AND multi_return_ratio > 0.3 THEN 'vegetation'\n                WHEN ground_z IS NOT NULL\n                     AND (avg_z - ground_z) > 3.0 THEN 'building'\n                ELSE 'ground'\n            END AS dominant_class\n        FROM base\n    \"\"\")\n    print(\"Done.\")\nelse:\n    print(f\"Table {DDB_TABLE} exists, skipping rebuild. Set FORCE_REBUILD = True to re-reduce.\")\n\ncon.sql(f\"SELECT COUNT(*) AS total_hex FROM {DDB_TABLE}\").show()\ncon.sql(f\"\"\"\n    SELECT dominant_class, COUNT(*) AS hex_count \n    FROM {DDB_TABLE} GROUP BY 1 ORDER BY 2 DESC\n\"\"\").show()\ncon.close()"
  },
  {
   "cell_type": "markdown",
   "id": "viz1-header",
   "metadata": {},
   "source": [
    "## Viz 1: Simple elevation map (Inferno by max_z)\n",
    "All hex, single layer, single colormap. Sanity check that the data looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "viz-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Viz 1: Simple elevation map (Inferno by max_z) ---\n",
    "# Sanity check — all hex, single layer, single colormap. Uncomment to run.\n",
    "#\n",
    "# from lonboard import Map, H3HexagonLayer\n",
    "# from arro3.core import Table\n",
    "# from lonboard.colormap import apply_continuous_cmap\n",
    "# from palettable.matplotlib import Inferno_20\n",
    "# from matplotlib.colors import Normalize\n",
    "#\n",
    "# con = duckdb.connect(DB_PATH, read_only=True)\n",
    "# con.sql(\"LOAD h3\")\n",
    "# df = con.sql(f\"\"\"\n",
    "#     SELECT h3_h3_to_string(hex) AS hex, max_z, cnt\n",
    "#     FROM {DDB_TABLE}\n",
    "#     WHERE cnt > {MIN_CNT}\n",
    "# \"\"\").fetch_arrow_table()\n",
    "# con.close()\n",
    "#\n",
    "# table = Table.from_arrow(df)\n",
    "# max_z = np.nan_to_num(np.array(pc.fill_null(df['max_z'], 0)), nan=0)\n",
    "# norm = Normalize(vmin=max_z.min(), vmax=np.percentile(max_z, 99), clip=True)\n",
    "# colors = apply_continuous_cmap(norm(max_z), Inferno_20)\n",
    "#\n",
    "# layer = H3HexagonLayer(\n",
    "#     table,\n",
    "#     get_hexagon=table['hex'],\n",
    "#     get_fill_color=colors,\n",
    "#     extruded=True,\n",
    "#     get_elevation=max_z,\n",
    "#     elevation_scale=3,\n",
    "#     stroked=False,\n",
    "#     opacity=1,\n",
    "#     coverage=1,\n",
    "# )\n",
    "#\n",
    "# Map(\n",
    "#     layers=[layer],\n",
    "#     view_state={'longitude': -122.44, 'latitude': 37.76, 'zoom': 12, 'pitch': 60, 'bearing': 30},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz2-header",
   "metadata": {},
   "source": "## Viz 2: Classification + height — subdued cmaps, ground opaque\n\n- **Ground + Water**: LaJolla by `ground_z`, alpha 255 (fully opaque base layer)\n- **Building**: Teal_7_r by `structure_height`\n- **Vegetation**: solid pale green\n- **Bridge**: solid gold\n\nAlpha: ground/water = 255, structures/veg/bridge much lower (~100) so the ground reads as terrain."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-classification",
   "metadata": {},
   "outputs": [],
   "source": "from lonboard import Map, H3HexagonLayer\nfrom arro3.core import Table\nfrom lonboard.colormap import apply_continuous_cmap\nfrom palettable.scientific.sequential import LaJolla_20\nfrom palettable.cartocolors.sequential import Teal_7_r\nfrom matplotlib.colors import Normalize\n\n# --- Load data ---\ncon = duckdb.connect(DB_PATH, read_only=True)\ncon.sql(\"LOAD h3\")\ndf = con.sql(f\"\"\"\n    SELECT h3_h3_to_string(hex) AS hex, avg_z, ground_z, structure_height, dominant_class, cnt\n    FROM {DDB_TABLE}\n    WHERE cnt > {MIN_CNT}\n\"\"\").fetch_arrow_table()\ncon.close()\n\ntable = Table.from_arrow(df)\nn = len(df)\n\n# --- Extract arrays ---\navg_z = np.nan_to_num(np.array(pc.fill_null(df['avg_z'], 0)), nan=0)\nground_z = np.nan_to_num(np.array(pc.fill_null(df['ground_z'], 0)), nan=0)\nstruct_h = np.clip(np.nan_to_num(np.array(pc.fill_null(df['structure_height'], 0)), nan=0), 0, None)\nclasses = np.asarray(df.column('dominant_class')).astype(str)\ncnt = np.array(df.column('cnt'))\n\n# --- Extrusion: ground/water by ground_z, structures by avg_z ---\nelev = np.where((classes == 'ground') | (classes == 'water'), ground_z, avg_z)\n\n# --- Normalizers ---\nground_pos = ground_z[ground_z > 0]\nnorm_elev = Normalize(\n    vmin=np.percentile(ground_pos, 1) if len(ground_pos) else 0,\n    vmax=np.percentile(ground_pos, 99) if len(ground_pos) else 1,\n    clip=True\n)\nstruct_pos = struct_h[struct_h > 0]\nnorm_struct = Normalize(vmin=0, vmax=np.percentile(struct_pos, 95) if len(struct_pos) else 1, clip=True)\n\n# --- Per-class coloring ---\ncolors_rgb = np.zeros((n, 3), dtype=np.uint8)\n\n# Ground + Water: LaJolla by ground_z\nm_gw = (classes == 'ground') | (classes == 'water')\nif m_gw.any():\n    colors_rgb[m_gw] = apply_continuous_cmap(norm_elev(ground_z[m_gw]), LaJolla_20)\n\n# Building: Teal_7_r by structure_height\nm_bld = classes == 'building'\nif m_bld.any():\n    colors_rgb[m_bld] = apply_continuous_cmap(norm_struct(struct_h[m_bld]), Teal_7_r)\n\n# Vegetation: solid pale green\nm_veg = classes == 'vegetation'\nif m_veg.any():\n    colors_rgb[m_veg] = [144, 190, 109]\n\n# Bridge: solid gold\nm_brg = classes == 'bridge'\nif m_brg.any():\n    colors_rgb[m_brg] = [218, 165, 27]\n\n# --- Alpha: ground/water = 255, everything else = 100 ---\nalpha = np.full(n, 100, dtype=np.uint8)\nalpha[m_gw] = 255\n\n# --- Combine RGBA ---\ncolors = np.concatenate([colors_rgb, alpha.reshape(-1, 1)], axis=1)\n\nprint(f\"{n:,} hex | Classes: {dict(zip(*np.unique(classes, return_counts=True)))}\")\nprint(f\"Struct height p95: {np.percentile(struct_pos, 95):.1f}m | Ground elev range: [{norm_elev.vmin:.1f}, {norm_elev.vmax:.1f}]m\")\n\nlayer = H3HexagonLayer(\n    table,\n    get_hexagon=table['hex'],\n    get_fill_color=colors,\n    extruded=True,\n    get_elevation=elev,\n    elevation_scale=3,\n    stroked=False,\n    coverage=1,\n)\n\nMap(\n    layers=[layer],\n    view_state={'longitude': -122.44, 'latitude': 37.76, 'zoom': 12, 'pitch': 60, 'bearing': 30},\n)"
  },
  {
   "cell_type": "markdown",
   "id": "viz3-header",
   "metadata": {},
   "source": [
    "## Viz 3: ASPRS classification colors (flat)\n",
    "Standard LiDAR class colors — quick check that dominant_class assignment looks reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "viz-asprs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Viz 3: ASPRS classification colors (flat) ---\n",
    "# Quick check that dominant_class assignment looks reasonable. Uncomment to run.\n",
    "#\n",
    "# from lonboard import Map, H3HexagonLayer\n",
    "# from arro3.core import Table\n",
    "#\n",
    "# con = duckdb.connect(DB_PATH, read_only=True)\n",
    "# con.sql(\"LOAD h3\")\n",
    "# df = con.sql(f\"\"\"\n",
    "#     SELECT h3_h3_to_string(hex) AS hex, max_z, dominant_class, cnt\n",
    "#     FROM {DDB_TABLE}\n",
    "#     WHERE cnt > {MIN_CNT}\n",
    "# \"\"\").fetch_arrow_table()\n",
    "# con.close()\n",
    "#\n",
    "# table = Table.from_arrow(df)\n",
    "# max_z = np.nan_to_num(np.array(pc.fill_null(df['max_z'], 0)), nan=0)\n",
    "# classes = np.asarray(df.column('dominant_class')).astype(str)\n",
    "#\n",
    "# # Colorblind-safe classification colors (no red-green distinction)\n",
    "# CLASS_COLORS = {\n",
    "#     'ground':     [186, 148, 86, 255],   # brown\n",
    "#     'building':   [230, 159, 0, 255],     # orange (colorblind-safe, replaces red)\n",
    "#     'vegetation': [0, 114, 178, 255],     # blue (colorblind-safe, replaces green)\n",
    "#     'water':      [86, 180, 233, 255],    # sky blue\n",
    "#     'bridge':     [160, 160, 160, 255],   # gray\n",
    "# }\n",
    "# DEFAULT_COLOR = [200, 200, 200, 255]\n",
    "# colors = np.array([CLASS_COLORS.get(c, DEFAULT_COLOR) for c in classes], dtype=np.uint8)\n",
    "#\n",
    "# layer = H3HexagonLayer(\n",
    "#     table,\n",
    "#     get_hexagon=table['hex'],\n",
    "#     get_fill_color=colors,\n",
    "#     extruded=True,\n",
    "#     get_elevation=max_z,\n",
    "#     elevation_scale=3,\n",
    "#     stroked=False,\n",
    "#     opacity=1,\n",
    "#     coverage=1,\n",
    "# )\n",
    "#\n",
    "# Map(\n",
    "#     layers=[layer],\n",
    "#     view_state={'longitude': -122.44, 'latitude': 37.76, 'zoom': 12, 'pitch': 60, 'bearing': 30},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Reference: PDAL Pipeline (already ran — ~50 min)\n",
    "\n",
    "The cells below are the pipeline that built `raw_hex_batches`. \n",
    "**Do NOT re-run** unless you want to rebuild from scratch. The data is in the .ddb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pipeline-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pipeline Configuration (reference only) ---\n",
    "EPT_URL = \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/CA_SanFrancisco_1_B23/ept.json\"\n",
    "SRC_CRS = 'EPSG:3857'\n",
    "DST_CRS = 'EPSG:4326'\n",
    "TILE_ZOOM = 16\n",
    "MAX_WORKERS = 14\n",
    "SUB_RESOLUTION = None\n",
    "BBOX = [-13638426.0, 4536715.0, -13617318.0, 4556481.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pipeline-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_con():\n",
    "#     \"\"\"In-memory connection for workers. LOAD only, no INSTALL.\"\"\"\n",
    "#     con = duckdb.connect()\n",
    "#     con.sql(\"\"\"\n",
    "#         SET temp_directory = './tmp';\n",
    "#         SET memory_limit = '512MB';\n",
    "#         LOAD h3;\n",
    "#         LOAD httpfs;\n",
    "#         LOAD spatial;\n",
    "#         SET enable_progress_bar = false;\n",
    "#     \"\"\")\n",
    "#     return con\n",
    "#\n",
    "# def process_tile_to_h3(tile):\n",
    "#     \"\"\"Worker: PDAL Points -> Rich H3 Aggregates -> Returns Arrow Table\"\"\"\n",
    "#     tb = mercantile.xy_bounds(tile)\n",
    "#     bounds = f\"([{tb.left},{tb.right}],[{tb.bottom},{tb.top}])\"\n",
    "#     reader_opts = {\"filename\": EPT_URL, \"bounds\": bounds}\n",
    "#     if SUB_RESOLUTION:\n",
    "#         reader_opts[\"resolution\"] = SUB_RESOLUTION\n",
    "#     try:\n",
    "#         pipeline = pdal.Reader.ept(**reader_opts).pipeline()\n",
    "#         count = pipeline.execute()\n",
    "#         if count == 0 or len(pipeline.arrays) == 0:\n",
    "#             return None\n",
    "#         arr = pipeline.arrays[0]\n",
    "#         if len(arr) == 0: return None\n",
    "#         arrow_tbl = pa.Table.from_arrays(\n",
    "#             [\n",
    "#                 pa.array(arr['X']), pa.array(arr['Y']), pa.array(arr['Z']),\n",
    "#                 pa.array(arr['Classification']),\n",
    "#                 pa.array(arr['Intensity']),\n",
    "#                 pa.array(arr['ReturnNumber']),\n",
    "#                 pa.array(arr['NumberOfReturns']),\n",
    "#             ],\n",
    "#             names=['X', 'Y', 'Z', 'Classification', 'Intensity', 'ReturnNumber', 'NumberOfReturns']\n",
    "#         )\n",
    "#         con = get_con()\n",
    "#         con.register('tile_data', arrow_tbl)\n",
    "#         hex_summary = con.sql(f\"\"\"\n",
    "#             SELECT \n",
    "#                 h3_latlng_to_cell(\n",
    "#                     ST_Y(ST_Transform(ST_Point(X, Y), '{SRC_CRS}', '{DST_CRS}', always_xy := true)), \n",
    "#                     ST_X(ST_Transform(ST_Point(X, Y), '{SRC_CRS}', '{DST_CRS}', always_xy := true)), \n",
    "#                     {H3_RES}\n",
    "#                 ) AS hex,\n",
    "#                 AVG(Z) AS avg_z, MIN(Z) AS min_z, MAX(Z) AS max_z,\n",
    "#                 MAX(Z) - MIN(Z) AS z_range, COUNT(*) AS cnt,\n",
    "#                 AVG(Z) FILTER (WHERE Classification = 2) AS ground_z,\n",
    "#                 COUNT(*) FILTER (WHERE Classification = 2) AS ground_cnt,\n",
    "#                 COUNT(*) FILTER (WHERE Classification = 6) AS building_cnt,\n",
    "#                 COUNT(*) FILTER (WHERE Classification = 17) AS bridge_cnt,\n",
    "#                 COUNT(*) FILTER (WHERE Classification IN (3,4,5)) AS veg_cnt,\n",
    "#                 COUNT(*) FILTER (WHERE Classification = 9) AS water_cnt,\n",
    "#                 AVG(Intensity) AS avg_intensity,\n",
    "#                 COUNT(*) FILTER (WHERE NumberOfReturns > 1)::DOUBLE / NULLIF(COUNT(*), 0) AS multi_return_ratio,\n",
    "#                 AVG(Z) FILTER (WHERE ReturnNumber = 1) - AVG(Z) FILTER (WHERE ReturnNumber = NumberOfReturns AND NumberOfReturns > 1) AS canopy_height\n",
    "#             FROM tile_data\n",
    "#             GROUP BY 1\n",
    "#         \"\"\").fetch_arrow_table()\n",
    "#         con.unregister('tile_data')\n",
    "#         con.close()\n",
    "#         return hex_summary\n",
    "#     except Exception as e:\n",
    "#         print(f\"  TILE FAILED {tile}: {e}\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pipeline-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_pipeline():\n",
    "#     import os, time, mercantile, pyarrow as pa, pdal\n",
    "#     os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)\n",
    "#     sw = mercantile.lnglat(BBOX[0], BBOX[1])\n",
    "#     ne = mercantile.lnglat(BBOX[2], BBOX[3])\n",
    "#     tiles = list(mercantile.tiles(sw.lng, sw.lat, ne.lng, ne.lat, zooms=[TILE_ZOOM]))\n",
    "#     con = duckdb.connect(DB_PATH)\n",
    "#     con.sql(\"\"\"\n",
    "#         CREATE OR REPLACE TABLE raw_hex_batches (\n",
    "#             hex UBIGINT,\n",
    "#             avg_z DOUBLE, min_z DOUBLE, max_z DOUBLE, z_range DOUBLE, cnt BIGINT,\n",
    "#             ground_z DOUBLE, ground_cnt BIGINT,\n",
    "#             building_cnt BIGINT, bridge_cnt BIGINT, veg_cnt BIGINT, water_cnt BIGINT,\n",
    "#             avg_intensity DOUBLE, multi_return_ratio DOUBLE, canopy_height DOUBLE\n",
    "#         )\n",
    "#     \"\"\")\n",
    "#     con.close()\n",
    "#     print(f\"Processing {len(tiles)} tiles with {MAX_WORKERS} workers...\")\n",
    "#     start = time.time()\n",
    "#     FLUSH_EVERY = 50\n",
    "#     pending_tables = []\n",
    "#     def flush_to_db(tables):\n",
    "#         if not tables: return\n",
    "#         combined = pa.concat_tables(tables)\n",
    "#         con = duckdb.connect(DB_PATH)\n",
    "#         con.sql(\"INSERT INTO raw_hex_batches SELECT * FROM combined\")\n",
    "#         con.close()\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "#         futures = {executor.submit(process_tile_to_h3, t): t for t in tiles}\n",
    "#         for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "#             result = future.result()\n",
    "#             if result: pending_tables.append(result)\n",
    "#             if len(pending_tables) >= FLUSH_EVERY:\n",
    "#                 flush_to_db(pending_tables)\n",
    "#                 pending_tables = []\n",
    "#             if i % 100 == 0:\n",
    "#                 print(f\"Batch {i}/{len(tiles)} | Time: {time.time()-start:.1f}s\")\n",
    "#     flush_to_db(pending_tables)\n",
    "#     print(f\"Pipeline done in {(time.time()-start)/60:.1f} min\")\n",
    "#\n",
    "# run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}