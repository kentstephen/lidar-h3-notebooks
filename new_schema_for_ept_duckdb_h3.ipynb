{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb8e1463",
   "metadata": {},
   "source": [
    "# CLAUDE please update this notebook with a new branch where you change to meet the latest TODO, new branch:\n",
    "\n",
    "⏺ Added the TODO. The short version: pull Classification, Intensity, ReturnNumber, NumberOfReturns into the worker Arrow table, then aggregate\n",
    "  per-hex class counts, ground elevation, structure height, vegetation density, and canopy height. That gives you land-use coloring, true building\n",
    "  heights above ground, suspended bridge hex, and vegetation density — all from the same EPT source you're already querying.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b067055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- USER PARAMETERS ---\n",
    "EPT_URL = \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/CA_SanFrancisco_1_B23/ept.json\"\n",
    "H3_RES = 13\n",
    "DDB_TABLE = f\"san_fran_rich_res_{H3_RES}\"\n",
    "SRC_CRS = 'EPSG:3857'\n",
    "DST_CRS = 'EPSG:4326'\n",
    "DB_PATH = 'duckdb/san_fran_ept_lpc.ddb'\n",
    "TILE_ZOOM = 16\n",
    "MAX_WORKERS = 14\n",
    "SUB_RESOLUTION = None  # Example: 1.0 (meters) to thin the data as it downloads\n",
    "BBOX = [-13638426.0, 4536715.0, -13617318.0, 4556481.0] # [min_x, min_y, max_x, max_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7e3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install extensions globally (only needed once)\n",
    "import duckdb\n",
    "duckdb.sql(\"INSTALL h3 FROM community\")\n",
    "duckdb.sql(\"INSTALL httpfs\")\n",
    "duckdb.sql(\"INSTALL spatial\")\n",
    "# duckdb.sql(\"INSTALL pdal FROM community\")\n",
    "def get_con():\n",
    "    \"\"\"In-memory connection for workers. LOAD only, no INSTALL.\"\"\"\n",
    "    con = duckdb.connect()\n",
    "    con.sql(\"\"\"\n",
    "        SET temp_directory = './tmp';\n",
    "        SET memory_limit = '512MB';\n",
    "     --   SET s3_region = 'us-west-2';\n",
    "        LOAD h3;\n",
    "        LOAD httpfs;\n",
    "        LOAD spatial;\n",
    "        SET enable_progress_bar = false;\n",
    "    \"\"\")\n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ruftcl88k4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdal\n",
    "import pyarrow as pa\n",
    "import duckdb\n",
    "import mercantile\n",
    "import concurrent.futures\n",
    "import time\n",
    "import os\n",
    "\n",
    "def process_tile_to_h3(tile):\n",
    "    \"\"\"Worker: PDAL Points -> Rich H3 Aggregates -> Returns Arrow Table\"\"\"\n",
    "    tb = mercantile.xy_bounds(tile)\n",
    "    bounds = f\"([{tb.left},{tb.right}],[{tb.bottom},{tb.top}])\"\n",
    "    \n",
    "    reader_opts = {\"filename\": EPT_URL, \"bounds\": bounds}\n",
    "    if SUB_RESOLUTION:\n",
    "        reader_opts[\"resolution\"] = SUB_RESOLUTION\n",
    "\n",
    "    try:\n",
    "        pipeline = pdal.Reader.ept(**reader_opts).pipeline()\n",
    "        count = pipeline.execute()\n",
    "        if count == 0 or len(pipeline.arrays) == 0:\n",
    "            return None\n",
    "        arr = pipeline.arrays[0]\n",
    "        if len(arr) == 0: return None\n",
    "\n",
    "        # Pull X, Y, Z + Classification, Intensity, ReturnNumber, NumberOfReturns\n",
    "        arrow_tbl = pa.Table.from_arrays(\n",
    "            [\n",
    "                pa.array(arr['X']), pa.array(arr['Y']), pa.array(arr['Z']),\n",
    "                pa.array(arr['Classification']),\n",
    "                pa.array(arr['Intensity']),\n",
    "                pa.array(arr['ReturnNumber']),\n",
    "                pa.array(arr['NumberOfReturns']),\n",
    "            ],\n",
    "            names=['X', 'Y', 'Z', 'Classification', 'Intensity', 'ReturnNumber', 'NumberOfReturns']\n",
    "        )\n",
    "        \n",
    "        con = get_con()\n",
    "        con.register('tile_data', arrow_tbl)\n",
    "        hex_summary = con.sql(f\"\"\"\n",
    "            SELECT \n",
    "                h3_latlng_to_cell(\n",
    "                    ST_Y(ST_Transform(ST_Point(X, Y), '{SRC_CRS}', '{DST_CRS}', always_xy := true)), \n",
    "                    ST_X(ST_Transform(ST_Point(X, Y), '{SRC_CRS}', '{DST_CRS}', always_xy := true)), \n",
    "                    {H3_RES}\n",
    "                ) AS hex,\n",
    "                -- Elevation stats\n",
    "                AVG(Z) AS avg_z,\n",
    "                MIN(Z) AS min_z,\n",
    "                MAX(Z) AS max_z,\n",
    "                MAX(Z) - MIN(Z) AS z_range,\n",
    "                COUNT(*) AS cnt,\n",
    "                -- Ground elevation (Classification 2)\n",
    "                AVG(Z) FILTER (WHERE Classification = 2) AS ground_z,\n",
    "                COUNT(*) FILTER (WHERE Classification = 2) AS ground_cnt,\n",
    "                -- Building (Classification 6)\n",
    "                COUNT(*) FILTER (WHERE Classification = 6) AS building_cnt,\n",
    "                -- Bridge (Classification 17)\n",
    "                COUNT(*) FILTER (WHERE Classification = 17) AS bridge_cnt,\n",
    "                -- Vegetation (Classification 3,4,5)\n",
    "                COUNT(*) FILTER (WHERE Classification IN (3,4,5)) AS veg_cnt,\n",
    "                -- Water (Classification 9)\n",
    "                COUNT(*) FILTER (WHERE Classification = 9) AS water_cnt,\n",
    "                -- Intensity\n",
    "                AVG(Intensity) AS avg_intensity,\n",
    "                -- Vegetation density: ratio of multi-return points\n",
    "                COUNT(*) FILTER (WHERE NumberOfReturns > 1)::DOUBLE / NULLIF(COUNT(*), 0) AS multi_return_ratio,\n",
    "                -- Canopy height: first return Z - last return Z\n",
    "                AVG(Z) FILTER (WHERE ReturnNumber = 1) - AVG(Z) FILTER (WHERE ReturnNumber = NumberOfReturns AND NumberOfReturns > 1) AS canopy_height\n",
    "            FROM tile_data\n",
    "            GROUP BY 1\n",
    "        \"\"\").fetch_arrow_table()\n",
    "        con.unregister('tile_data')\n",
    "        con.close()\n",
    "        return hex_summary\n",
    "    except Exception as e:\n",
    "        print(f\"  TILE FAILED {tile}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fced454b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1188 tiles with 14 workers...\n",
      "Batch 0/1188 | Time: 1.1s\n",
      "Batch 100/1188 | Time: 78.1s\n",
      "Batch 200/1188 | Time: 404.7s\n",
      "Batch 300/1188 | Time: 842.3s\n",
      "Batch 400/1188 | Time: 1318.8s\n",
      "Batch 500/1188 | Time: 1776.8s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853c41b5ddd742fbacf32b66adb81510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600/1188 | Time: 2168.7s\n",
      "Batch 700/1188 | Time: 2539.3s\n",
      "Batch 800/1188 | Time: 2829.5s\n",
      "Batch 900/1188 | Time: 2973.1s\n",
      "Batch 1000/1188 | Time: 3021.9s\n",
      "Batch 1100/1188 | Time: 3031.9s\n",
      "Finalizing global reduction...\n",
      "┌───────────┐\n",
      "│ total_hex │\n",
      "│   int64   │\n",
      "├───────────┤\n",
      "│   2958715 │\n",
      "└───────────┘\n",
      "\n",
      "┌────────────────┬───────────┐\n",
      "│ dominant_class │ hex_count │\n",
      "│    varchar     │   int64   │\n",
      "├────────────────┼───────────┤\n",
      "│ ground         │   2490172 │\n",
      "│ building       │    452836 │\n",
      "│ bridge         │     14660 │\n",
      "│ water          │       949 │\n",
      "│ vegetation     │        98 │\n",
      "└────────────────┴───────────┘\n",
      "\n",
      "Elapsed: 50.7 min\n"
     ]
    }
   ],
   "source": [
    "def run_pipeline():\n",
    "    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)\n",
    "    \n",
    "    # 1. Generate Tile List\n",
    "    sw = mercantile.lnglat(BBOX[0], BBOX[1])\n",
    "    ne = mercantile.lnglat(BBOX[2], BBOX[3])\n",
    "    tiles = list(mercantile.tiles(sw.lng, sw.lat, ne.lng, ne.lat, zooms=[TILE_ZOOM]))\n",
    "    \n",
    "    # 2. Initialize Persistent Storage — open briefly, then close\n",
    "    con = duckdb.connect(DB_PATH)\n",
    "    con.sql(\"\"\"\n",
    "        CREATE OR REPLACE TABLE raw_hex_batches (\n",
    "            hex UBIGINT,\n",
    "            avg_z DOUBLE, min_z DOUBLE, max_z DOUBLE, z_range DOUBLE, cnt BIGINT,\n",
    "            ground_z DOUBLE, ground_cnt BIGINT,\n",
    "            building_cnt BIGINT, bridge_cnt BIGINT, veg_cnt BIGINT, water_cnt BIGINT,\n",
    "            avg_intensity DOUBLE, multi_return_ratio DOUBLE, canopy_height DOUBLE\n",
    "        )\n",
    "    \"\"\")\n",
    "    con.close()\n",
    "\n",
    "    print(f\"Processing {len(tiles)} tiles with {MAX_WORKERS} workers...\")\n",
    "    start = time.time()\n",
    "\n",
    "    # 3. Parallel Process — accumulate Arrow tables in memory, flush in batches\n",
    "    FLUSH_EVERY = 50\n",
    "    pending_tables = []\n",
    "\n",
    "    def flush_to_db(tables):\n",
    "        if not tables:\n",
    "            return\n",
    "        combined = pa.concat_tables(tables)\n",
    "        con = duckdb.connect(DB_PATH)\n",
    "        con.sql(\"INSERT INTO raw_hex_batches SELECT * FROM combined\")\n",
    "        con.close()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(process_tile_to_h3, t): t for t in tiles}\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            pa_temp_table = future.result()\n",
    "            if pa_temp_table:\n",
    "                pending_tables.append(pa_temp_table)\n",
    "            \n",
    "            if len(pending_tables) >= FLUSH_EVERY:\n",
    "                flush_to_db(pending_tables)\n",
    "                pending_tables = []\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Batch {i}/{len(tiles)} | Time: {time.time()-start:.1f}s\")\n",
    "\n",
    "    # Flush remaining\n",
    "    flush_to_db(pending_tables)\n",
    "\n",
    "    # 4. Final Global Reduction — merge hex spanning tile boundaries\n",
    "    print(\"Finalizing global reduction...\")\n",
    "    con = duckdb.connect(DB_PATH)\n",
    "    con.sql(\"LOAD h3\")\n",
    "    con.sql(f\"\"\"\n",
    "        CREATE OR REPLACE TABLE {DDB_TABLE} AS\n",
    "        SELECT \n",
    "            hex,\n",
    "            h3_cell_to_lat(hex) AS lat,\n",
    "            h3_cell_to_lng(hex) AS lng,\n",
    "            -- Elevation: weighted avg, global min/max\n",
    "            SUM(avg_z * cnt) / SUM(cnt) AS avg_z,\n",
    "            MIN(min_z) AS min_z,\n",
    "            MAX(max_z) AS max_z,\n",
    "            MAX(max_z) - MIN(min_z) AS z_range,\n",
    "            SUM(cnt) AS cnt,\n",
    "            -- Ground: weighted avg across tiles\n",
    "            SUM(ground_z * ground_cnt) / NULLIF(SUM(ground_cnt), 0) AS ground_z,\n",
    "            SUM(ground_cnt) AS ground_cnt,\n",
    "            -- Structure height above ground\n",
    "            MAX(max_z) - (SUM(ground_z * ground_cnt) / NULLIF(SUM(ground_cnt), 0)) AS structure_height,\n",
    "            -- Classification counts\n",
    "            SUM(building_cnt) AS building_cnt,\n",
    "            SUM(bridge_cnt) AS bridge_cnt,\n",
    "            SUM(veg_cnt) AS veg_cnt,\n",
    "            SUM(water_cnt) AS water_cnt,\n",
    "            -- Intensity: weighted avg\n",
    "            SUM(avg_intensity * cnt) / SUM(cnt) AS avg_intensity,\n",
    "            -- Multi-return ratio: weighted avg\n",
    "            SUM(multi_return_ratio * cnt) / SUM(cnt) AS multi_return_ratio,\n",
    "            -- Canopy height: weighted avg (only where we have data)\n",
    "            SUM(canopy_height * veg_cnt) / NULLIF(SUM(veg_cnt), 0) AS canopy_height,\n",
    "            -- Dominant class\n",
    "            CASE \n",
    "                WHEN SUM(building_cnt) >= SUM(ground_cnt) AND SUM(building_cnt) >= SUM(veg_cnt) THEN 'building'\n",
    "                WHEN SUM(veg_cnt) >= SUM(ground_cnt) THEN 'vegetation'\n",
    "                WHEN SUM(water_cnt) > SUM(cnt) * 0.5 THEN 'water'\n",
    "                WHEN SUM(bridge_cnt) > 0 THEN 'bridge'\n",
    "                ELSE 'ground'\n",
    "            END AS dominant_class\n",
    "        FROM raw_hex_batches\n",
    "        GROUP BY 1\n",
    "    \"\"\")\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    con.sql(f\"SELECT COUNT(*) as total_hex FROM {DDB_TABLE}\").show()\n",
    "    con.sql(f\"\"\"\n",
    "        SELECT dominant_class, COUNT(*) as hex_count \n",
    "        FROM {DDB_TABLE} \n",
    "        GROUP BY 1 ORDER BY 2 DESC\n",
    "    \"\"\").show()\n",
    "    print(f\"Elapsed: {elapsed/60:.1f} min\")\n",
    "    con.close()\n",
    "\n",
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vh2qfnasnaj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run ONLY the final reduction with fixed classification + structure_height\n",
    "# No PDAL needed — just re-aggregates raw_hex_batches (seconds)\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect(DB_PATH)\n",
    "con.sql(\"LOAD h3\")\n",
    "con.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {DDB_TABLE} AS\n",
    "    SELECT \n",
    "        hex,\n",
    "        h3_cell_to_lat(hex) AS lat,\n",
    "        h3_cell_to_lng(hex) AS lng,\n",
    "        -- Elevation: weighted avg, global min/max\n",
    "        SUM(avg_z * cnt) / SUM(cnt) AS avg_z,\n",
    "        MIN(min_z) AS min_z,\n",
    "        MAX(max_z) AS max_z,\n",
    "        MAX(max_z) - MIN(min_z) AS z_range,\n",
    "        SUM(cnt) AS cnt,\n",
    "        -- Ground: weighted avg across tiles\n",
    "        SUM(ground_z * ground_cnt) / NULLIF(SUM(ground_cnt), 0) AS ground_z,\n",
    "        SUM(ground_cnt) AS ground_cnt,\n",
    "        -- Structure height: avg_z - ground_z (robust to max_z outliers)\n",
    "        (SUM(avg_z * cnt) / SUM(cnt)) - (SUM(ground_z * ground_cnt) / NULLIF(SUM(ground_cnt), 0)) AS structure_height,\n",
    "        -- Classification counts\n",
    "        SUM(building_cnt) AS building_cnt,\n",
    "        SUM(bridge_cnt) AS bridge_cnt,\n",
    "        SUM(veg_cnt) AS veg_cnt,\n",
    "        SUM(water_cnt) AS water_cnt,\n",
    "        -- Intensity: weighted avg\n",
    "        SUM(avg_intensity * cnt) / SUM(cnt) AS avg_intensity,\n",
    "        -- Multi-return ratio: weighted avg\n",
    "        SUM(multi_return_ratio * cnt) / SUM(cnt) AS multi_return_ratio,\n",
    "        -- Canopy height: weighted avg (only where we have data)\n",
    "        SUM(canopy_height * veg_cnt) / NULLIF(SUM(veg_cnt), 0) AS canopy_height,\n",
    "        -- Dominant class: argmax with minimum 10% threshold for non-ground\n",
    "        CASE\n",
    "            WHEN SUM(building_cnt) >= GREATEST(SUM(bridge_cnt), SUM(veg_cnt), SUM(water_cnt))\n",
    "                 AND SUM(building_cnt)::DOUBLE / SUM(cnt) > 0.1 THEN 'building'\n",
    "            WHEN SUM(bridge_cnt) >= GREATEST(SUM(building_cnt), SUM(veg_cnt), SUM(water_cnt))\n",
    "                 AND SUM(bridge_cnt)::DOUBLE / SUM(cnt) > 0.1 THEN 'bridge'\n",
    "            WHEN SUM(veg_cnt) >= GREATEST(SUM(building_cnt), SUM(bridge_cnt), SUM(water_cnt))\n",
    "                 AND SUM(veg_cnt)::DOUBLE / SUM(cnt) > 0.1 THEN 'vegetation'\n",
    "            WHEN SUM(water_cnt)::DOUBLE / SUM(cnt) > 0.3 THEN 'water'\n",
    "            ELSE 'ground'\n",
    "        END AS dominant_class\n",
    "    FROM raw_hex_batches\n",
    "    GROUP BY 1\n",
    "\"\"\")\n",
    "\n",
    "con.sql(f\"SELECT COUNT(*) as total_hex FROM {DDB_TABLE}\").show()\n",
    "con.sql(f\"\"\"\n",
    "    SELECT dominant_class, COUNT(*) as hex_count \n",
    "    FROM {DDB_TABLE} \n",
    "    GROUP BY 1 ORDER BY 2 DESC\n",
    "\"\"\").show()\n",
    "# Sanity: ground hex should have near-zero structure_height\n",
    "con.sql(f\"\"\"\n",
    "    SELECT dominant_class,\n",
    "           ROUND(AVG(structure_height), 1) AS avg_struct_h,\n",
    "           ROUND(PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY structure_height), 1) AS p99_struct_h,\n",
    "           ROUND(MAX(structure_height), 1) AS max_struct_h\n",
    "    FROM {DDB_TABLE}\n",
    "    GROUP BY 1 ORDER BY 2 DESC\n",
    "\"\"\").show()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D map — two layers: ground (Inferno by elevation) + structures (Viridis by height above ground)\n",
    "from lonboard import Map, H3HexagonLayer\n",
    "from arro3.core import Table\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from palettable.matplotlib import Viridis_20, Inferno_20\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "con = duckdb.connect(DB_PATH)\n",
    "con.sql(\"LOAD h3\")\n",
    "\n",
    "ground_df = con.sql(f\"\"\"\n",
    "    SELECT h3_h3_to_string(hex) AS hex, max_z, cnt\n",
    "    FROM {DDB_TABLE}\n",
    "    WHERE dominant_class = 'ground' AND cnt > 10\n",
    "\"\"\").fetch_arrow_table()\n",
    "\n",
    "struct_df = con.sql(f\"\"\"\n",
    "    SELECT h3_h3_to_string(hex) AS hex, max_z, structure_height, dominant_class, cnt\n",
    "    FROM {DDB_TABLE}\n",
    "    WHERE dominant_class != 'ground' AND cnt > 10\n",
    "\"\"\").fetch_arrow_table()\n",
    "con.close()\n",
    "\n",
    "# --- Ground layer: Inferno by max_z, extruded by max_z ---\n",
    "ground_tbl = Table.from_arrow(ground_df)\n",
    "ground_z = np.nan_to_num(np.array(pc.fill_null(ground_df[\"max_z\"], 0)), nan=0)\n",
    "norm_elev = Normalize(vmin=ground_z.min(), vmax=np.percentile(ground_z, 99), clip=True)\n",
    "ground_colors = apply_continuous_cmap(norm_elev(ground_z), Inferno_20)\n",
    "\n",
    "ground_layer = H3HexagonLayer(\n",
    "    ground_tbl,\n",
    "    get_hexagon=ground_tbl[\"hex\"],\n",
    "    get_fill_color=ground_colors,\n",
    "    extruded=True,\n",
    "    get_elevation=ground_z,\n",
    "    elevation_scale=3,\n",
    "    stroked=False,\n",
    "    opacity=1,\n",
    "    coverage=1,\n",
    ")\n",
    "\n",
    "# --- Structure layer: Viridis by structure_height, extruded by structure_height ---\n",
    "struct_tbl = Table.from_arrow(struct_df)\n",
    "struct_h = np.array(pc.fill_null(struct_df[\"structure_height\"], 0))\n",
    "struct_h = np.clip(struct_h, 0, None)\n",
    "struct_p99 = np.percentile(struct_h[struct_h > 0], 99) if (struct_h > 0).any() else 1\n",
    "norm_struct = Normalize(vmin=0, vmax=struct_p99, clip=True)\n",
    "struct_colors = apply_continuous_cmap(norm_struct(struct_h), Viridis_20)\n",
    "\n",
    "struct_layer = H3HexagonLayer(\n",
    "    struct_tbl,\n",
    "    get_hexagon=struct_tbl[\"hex\"],\n",
    "    get_fill_color=struct_colors,\n",
    "    extruded=True,\n",
    "    get_elevation=struct_h,\n",
    "    elevation_scale=3,\n",
    "    stroked=False,\n",
    "    opacity=1,\n",
    "    coverage=1,\n",
    ")\n",
    "\n",
    "Map(\n",
    "    layers=[ground_layer, struct_layer],\n",
    "    view_state={\"longitude\": -122.44, \"latitude\": 37.76, \"zoom\": 12, \"pitch\": 60, \"bearing\": 30},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29wgporumlm",
   "metadata": {},
   "source": [
    "## Dual-layer ground/structure map (WIP)\n",
    "The cell above splits hex into ground (Inferno by terrain elevation) and structures (Viridis by height above ground). Still confusing visually — H3HexagonLayer extrudes from z=0, so structures don't float above terrain. Needs deck.gl ColumnLayer with `getPosition=[lng, lat, ground_z]` to actually suspend buildings/bridges. Parking this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g6t83ma7no9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D elevation map — all hex, Inferno by max_z\n",
    "from lonboard import Map, H3HexagonLayer\n",
    "from arro3.core import Table\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from palettable.matplotlib import Inferno_20\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "con = duckdb.connect(DB_PATH)\n",
    "con.sql(\"LOAD h3\")\n",
    "df = con.sql(f\"\"\"\n",
    "    SELECT h3_h3_to_string(hex) AS hex, max_z, cnt\n",
    "    FROM {DDB_TABLE}\n",
    "    WHERE cnt > 10\n",
    "\"\"\").fetch_arrow_table()\n",
    "con.close()\n",
    "\n",
    "table = Table.from_arrow(df)\n",
    "max_z = np.nan_to_num(np.array(pc.fill_null(df[\"max_z\"], 0)), nan=0)\n",
    "\n",
    "norm = Normalize(vmin=max_z.min(), vmax=np.percentile(max_z, 99), clip=True)\n",
    "colors = apply_continuous_cmap(norm(max_z), Inferno_20)\n",
    "\n",
    "layer = H3HexagonLayer(\n",
    "    table,\n",
    "    get_hexagon=table[\"hex\"],\n",
    "    get_fill_color=colors,\n",
    "    extruded=True,\n",
    "    get_elevation=max_z,\n",
    "    elevation_scale=3,\n",
    "    stroked=False,\n",
    "    opacity=1,\n",
    "    coverage=1,\n",
    ")\n",
    "\n",
    "Map(\n",
    "    layers=[layer],\n",
    "    view_state={\"longitude\": -122.44, \"latitude\": 37.76, \"zoom\": 12, \"pitch\": 60, \"bearing\": 30},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ucgudv3okkp",
   "metadata": {},
   "source": [
    "## Classification map — ASPRS standard colors\n",
    "Standard LiDAR classification colors per hex: ground (brown), building (red), vegetation (green), water (blue), bridge (gray). Extruded by `max_z` for 3D terrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9zfh543j2y7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d77deee667548f5b5fc346d8e7ee58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(<lonboard._map.Map object at 0x11fda63d0>, VBox(children=(ErrorOutput(), ErrorOutput()), layout…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3D classification map — ASPRS standard colors, extruded by max_z\n",
    "from lonboard import Map, H3HexagonLayer\n",
    "from arro3.core import Table\n",
    "import numpy as np\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "con = duckdb.connect(DB_PATH)\n",
    "con.sql(\"LOAD h3\")\n",
    "df = con.sql(f\"\"\"\n",
    "    SELECT h3_h3_to_string(hex) AS hex, max_z, dominant_class, cnt\n",
    "    FROM {DDB_TABLE}\n",
    "    WHERE cnt > 10\n",
    "\"\"\").fetch_arrow_table()\n",
    "con.close()\n",
    "\n",
    "table = Table.from_arrow(df)\n",
    "max_z = np.nan_to_num(np.array(pc.fill_null(df[\"max_z\"], 0)), nan=0)\n",
    "classes = np.array(df.column(\"dominant_class\"))\n",
    "\n",
    "# ASPRS standard classification colors [R, G, B, A]\n",
    "CLASS_COLORS = {\n",
    "    'ground':     [186, 148, 86, 255],   # brown\n",
    "    'building':   [255, 0, 0, 255],      # red\n",
    "    'vegetation': [0, 160, 0, 255],      # green\n",
    "    'water':      [0, 100, 255, 255],    # blue\n",
    "    'bridge':     [160, 160, 160, 255],  # gray\n",
    "}\n",
    "DEFAULT_COLOR = [200, 200, 200, 255]\n",
    "\n",
    "colors = np.array([CLASS_COLORS.get(c, DEFAULT_COLOR) for c in classes], dtype=np.uint8)\n",
    "\n",
    "layer = H3HexagonLayer(\n",
    "    table,\n",
    "    get_hexagon=table[\"hex\"],\n",
    "    get_fill_color=colors,\n",
    "    extruded=True,\n",
    "    get_elevation=max_z,\n",
    "    elevation_scale=3,\n",
    "    stroked=False,\n",
    "    opacity=1,\n",
    "    coverage=1,\n",
    ")\n",
    "\n",
    "Map(\n",
    "    layers=[layer],\n",
    "    view_state={\"longitude\": -122.44, \"latitude\": 37.76, \"zoom\": 12, \"pitch\": 60, \"bearing\": 30},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sb1fyfoz5d",
   "metadata": {},
   "source": [
    "## Classification + height — per-class sequential colormaps, alpha by density\n",
    "Each class gets its own perceptually uniform gradient mapped by height. Ground = Viridis by `max_z`, Building = Bilbao (warm amber) by `structure_height`, Vegetation = Algae (teal-green), Bridge = Davos (cool blue-gray), Water = Deep (ocean blue) flat. Alpha = `log(cnt)` normalized to [80,255] — sparse hex fade out, dense hex stay opaque. All colorblind-safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463c70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification + height — per-class sequential colormaps, alpha by density\n",
    "from lonboard import Map, H3HexagonLayer\n",
    "from arro3.core import Table\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from palettable.cmocean.sequential import Algae_20, Deep_20\n",
    "from palettable.scientific.sequential import Bilbao_20, Davos_20\n",
    "from palettable.matplotlib import Viridis_20\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "import pyarrow.compute as pc\n",
    "import duckdb\n",
    "DB_PATH = 'duckdb/san_fran_ept_lpc.ddb'\n",
    "duckdb.sql(\"INSTALL h3 FROM community;\")\n",
    "con = duckdb.connect('duckdb/san_fran_ept_lpc.ddb')\n",
    "con.sql(\"LOAD h3\")\n",
    "df = con.sql(f\"\"\"\n",
    "    SELECT h3_h3_to_string(hex) AS hex, avg_z, ground_z, structure_height, dominant_class, cnt\n",
    "    FROM san_fran_rich_res_13\n",
    "    WHERE cnt > 10\n",
    "\"\"\").fetch_arrow_table()\n",
    "con.close()\n",
    "\n",
    "table = Table.from_arrow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe5120e-af23-42ce-bf4c-4ae614c63023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ze1rryl4mra",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = len(df)\n",
    "avg_z = np.nan_to_num(np.array(pc.fill_null(df[\"avg_z\"], 0)), nan=0)\n",
    "ground_z = np.nan_to_num(np.array(pc.fill_null(df[\"ground_z\"], 0)), nan=0)\n",
    "struct_h = np.clip(np.nan_to_num(np.array(pc.fill_null(df[\"structure_height\"], 0)), nan=0), 0, None)\n",
    "classes = np.array(df.column(\"dominant_class\"))\n",
    "cnt = np.array(df.column(\"cnt\"))\n",
    "\n",
    "# Extrusion: ground hex by ground_z, structure hex by avg_z\n",
    "elev = np.where(classes == 'ground', ground_z, avg_z)\n",
    "\n",
    "# Normalizers — color ground by ground_z, structures by structure_height\n",
    "norm_elev = Normalize(vmin=np.percentile(ground_z[ground_z > 0], 1) if (ground_z > 0).any() else 0,\n",
    "                      vmax=np.percentile(ground_z[ground_z > 0], 99) if (ground_z > 0).any() else 1, clip=True)\n",
    "struct_p99 = np.percentile(struct_h[struct_h > 0], 99) if (struct_h > 0).any() else 1\n",
    "norm_struct = Normalize(vmin=0, vmax=struct_p99, clip=True)\n",
    "\n",
    "elev_vals = norm_elev(ground_z)\n",
    "struct_vals = norm_struct(struct_h)\n",
    "\n",
    "# apply_continuous_cmap returns RGB (3ch) — build RGB array, add alpha after\n",
    "colors_rgb = np.zeros((n, 3), dtype=np.uint8)\n",
    "\n",
    "# Ground — Viridis by ground_z\n",
    "m = classes == 'ground'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(elev_vals[m], Viridis_20)\n",
    "\n",
    "# Building — Bilbao (warm amber) by structure_height\n",
    "m = classes == 'building'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Bilbao_20)\n",
    "\n",
    "# Vegetation — Algae (teal-green) by structure_height\n",
    "m = classes == 'vegetation'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Algae_20)\n",
    "\n",
    "# Bridge — Davos (cool blue-gray) by structure_height\n",
    "m = classes == 'bridge'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Davos_20)\n",
    "\n",
    "# Water — Deep (ocean blue) flat mid-tone\n",
    "m = classes == 'water'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(np.full(m.sum(), 0.5), Deep_20)\n",
    "\n",
    "# Alpha by point density — log(cnt) normalized to [80, 255]\n",
    "log_cnt = np.log1p(cnt.astype(np.float64))\n",
    "alpha_min, alpha_max = 80, 255\n",
    "lc_min, lc_max = log_cnt.min(), log_cnt.max()\n",
    "if lc_max > lc_min:\n",
    "    alpha = alpha_min + (log_cnt - lc_min) / (lc_max - lc_min) * (alpha_max - alpha_min)\n",
    "else:\n",
    "    alpha = np.full(n, alpha_max, dtype=np.float64)\n",
    "alpha = alpha.astype(np.uint8)\n",
    "\n",
    "# Combine RGB + alpha\n",
    "colors = np.concatenate([colors_rgb, alpha.reshape(-1, 1)], axis=1)\n",
    "\n",
    "layer = H3HexagonLayer(\n",
    "    table,\n",
    "    get_hexagon=table[\"hex\"],\n",
    "    get_fill_color=colors,\n",
    "    extruded=True,\n",
    "    get_elevation=elev,\n",
    "    elevation_scale=3,\n",
    "    stroked=False,\n",
    "\n",
    "    coverage=1,\n",
    ")\n",
    "\n",
    "Map(\n",
    "    layers=[layer],\n",
    "    view_state={\"longitude\": -122.44, \"latitude\": 37.76, \"zoom\": 12, \"pitch\": 60, \"bearing\": 30},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a127c016-ccf8-4d76-a009-0748ac136abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2952320, 4) uint8\n",
      "[[ 62 188 115 209]\n",
      " [ 62 188 115 210]\n",
      " [101 203  94 206]\n",
      " [ 36 169 130 206]\n",
      " [ 36 168 130 210]]\n",
      "(array(['bridge', 'building', 'ground', 'vegetation', 'water'],\n",
      "      dtype=object), array([  14660,  446595, 2490018,      98,     949]))\n",
      "ground indices: [0 1 2 3 4]\n",
      "[[ 62 188 115 209]\n",
      " [ 62 188 115 210]\n",
      " [101 203  94 206]\n",
      " [ 36 169 130 206]\n",
      " [ 36 168 130 210]]\n",
      "building indices: [18 19 20 27 47]\n",
      "[[255 255 255 206]\n",
      " [255 255 255 199]\n",
      " [255 255 255 199]\n",
      " [255 255 255 205]\n",
      " [255 255 255 206]]\n",
      "vegetation indices: [ 6796  6848  6862 25864 98496]\n",
      "[[215 249 208 197]\n",
      " [215 249 208 209]\n",
      " [215 249 208 206]\n",
      " [104 182 101 206]\n",
      " [215 249 208 205]]\n",
      "bridge indices: [71 73 74 78 87]\n",
      "[[ 45  87 148 205]\n",
      " [ 50  94 152 208]\n",
      " [ 17  43 112 206]\n",
      " [ 74 117 157 206]\n",
      " [ 28  63 131 205]]\n",
      "water indices: [ 2394  8167 17244 17245 17278]\n",
      "[[ 71 142 157 184]\n",
      " [ 71 142 157 188]\n",
      " [ 71 142 157 182]\n",
      " [ 71 142 157 184]\n",
      " [ 71 142 157 186]]\n"
     ]
    }
   ],
   "source": [
    "print(colors.shape, colors.dtype)\n",
    "print(colors[:5])\n",
    "# How many of each class?\n",
    "print(np.unique(classes, return_counts=True))\n",
    "\n",
    "# A few random indices per class\n",
    "for cls in [\"ground\", \"building\", \"vegetation\", \"bridge\", \"water\"]:\n",
    "    idx = np.where(classes == cls)[0][:5]\n",
    "    print(cls, \"indices:\", idx)\n",
    "    if len(idx) > 0:\n",
    "        print(colors[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0eb824-5800-4c8a-b78d-5ff8ae8ebf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = len(df)\n",
    "avg_z = np.nan_to_num(np.array(pc.fill_null(df[\"avg_z\"], 0)), nan=0)\n",
    "ground_z = np.nan_to_num(np.array(pc.fill_null(df[\"ground_z\"], 0)), nan=0)\n",
    "struct_h = np.clip(np.nan_to_num(np.array(pc.fill_null(df[\"structure_height\"], 0)), nan=0), 0, None)\n",
    "classes = np.array(df.column(\"dominant_class\"))\n",
    "cnt = np.array(df.column(\"cnt\"))\n",
    "\n",
    "# Extrusion: ground hex by ground_z, structure hex by avg_z\n",
    "elev = np.where(classes == 'ground', ground_z, avg_z)\n",
    "\n",
    "# Normalizers — color ground by ground_z, structures by structure_height\n",
    "norm_elev = Normalize(vmin=np.percentile(ground_z[ground_z > 0], 1) if (ground_z > 0).any() else 0,\n",
    "                      vmax=np.percentile(ground_z[ground_z > 0], 99) if (ground_z > 0).any() else 1, clip=True)\n",
    "struct_p99 = np.percentile(struct_h[struct_h > 0], 99) if (struct_h > 0).any() else 1\n",
    "norm_struct = Normalize(vmin=0, vmax=struct_p99, clip=True)\n",
    "\n",
    "elev_vals = norm_elev(ground_z)\n",
    "struct_vals = norm_struct(struct_h)\n",
    "\n",
    "# apply_continuous_cmap returns RGB (3ch) — build RGB array, add alpha after\n",
    "colors_rgb = np.zeros((n, 3), dtype=np.uint8)\n",
    "ground = apply_continuous_cmap(elev_vals, Viridis_20)\n",
    "building = apply_continuous_cmap(struct_vals, Bilbao_20)\n",
    "vegetation = apply_continuous_cmap(struct_vals, Algae_20)\n",
    "bridge = apply_continuous_cmap(struct_vals[m], Davos_20)\n",
    "water= apply_continuous_cmap(np.full(m.sum(), 0.5), Deep_20)\n",
    "# Ground — Viridis by ground_z\n",
    "m = classes == 'ground'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(elev_vals[m], Viridis_20)\n",
    "\n",
    "# Building — Bilbao (warm amber) by structure_height\n",
    "m = classes == 'building'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Bilbao_20)\n",
    "\n",
    "# Vegetation — Algae (teal-green) by structure_height\n",
    "m = classes == 'vegetation'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Algae_20)\n",
    "\n",
    "# Bridge — Davos (cool blue-gray) by structure_height\n",
    "m = classes == 'bridge'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Davos_20)\n",
    "\n",
    "# Water — Deep (ocean blue) flat mid-tone\n",
    "m = classes == 'water'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(np.full(m.sum(), 0.5), Deep_20)\n",
    "\n",
    "# Alpha by point density — log(cnt) normalized to [80, 255]\n",
    "log_cnt = np.log1p(cnt.astype(np.float64))\n",
    "alpha_min, alpha_max = 80, 255\n",
    "lc_min, lc_max = log_cnt.min(), log_cnt.max()\n",
    "if lc_max > lc_min:\n",
    "    alpha = alpha_min + (log_cnt - lc_min) / (lc_max - lc_min) * (alpha_max - alpha_min)\n",
    "else:\n",
    "    alpha = np.full(n, alpha_max, dtype=np.float64)\n",
    "alpha = alpha.astype(np.uint8)\n",
    "\n",
    "# Combine RGB + alpha\n",
    "colors = np.concatenate([colors_rgb, alpha.reshape(-1, 1)], axis=1)\n",
    "\n",
    "layer = H3HexagonLayer(\n",
    "    table,\n",
    "    get_hexagon=table[\"hex\"],\n",
    "    get_fill_color=colors,\n",
    "    extruded=True,\n",
    "    get_elevation=elev,\n",
    "    elevation_scale=3,\n",
    "    stroked=False,\n",
    "\n",
    "    coverage=1,\n",
    ")\n",
    "\n",
    "Map(\n",
    "    layers=[layer],\n",
    "    view_state={\"longitude\": -122.44, \"latitude\": 37.76, \"zoom\": 12, \"pitch\": 60, \"bearing\": 30},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68db8e47-bc40-4ec4-a6b6-85698dd6d7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xl703t56wt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vegetation density — color by multi_return_ratio, extrude by canopy_height\n",
    "# from matplotlib.colors import Normalize\n",
    "# from lonboard.colormap import apply_continuous_cmap\n",
    "# from palettable.cartocolors.sequential import BurgYl_7  # yellow-to-dark-green\n",
    "\n",
    "# veg_ratio = np.array(table[\"multi_return_ratio\"])\n",
    "# veg_ratio = np.nan_to_num(veg_ratio, nan=0)\n",
    "# norm = Normalize(vmin=0, vmax=np.percentile(veg_ratio[veg_ratio > 0], 95) if (veg_ratio > 0).any() else 1, clip=True)\n",
    "# veg_colors = apply_continuous_cmap(norm(veg_ratio), BurgYl_7)\n",
    "\n",
    "# canopy = np.array(table[\"canopy_height\"])\n",
    "# canopy = np.nan_to_num(canopy, nan=0)\n",
    "# canopy = np.clip(canopy, 0, None)\n",
    "\n",
    "# veg_layer = H3HexagonLayer(\n",
    "#     table,\n",
    "#     get_hexagon=table[\"hex\"],\n",
    "#     get_fill_color=veg_colors,\n",
    "#     extruded=True,\n",
    "#     get_elevation=canopy,\n",
    "#     elevation_scale=5,\n",
    "#     stroked=False,\n",
    "#     opacity=0.9,\n",
    "#     coverage=1,\n",
    "# )\n",
    "\n",
    "# Map(\n",
    "#     layers=[veg_layer],\n",
    "#     view_state={\"longitude\": -122.44, \"latitude\": 37.76, \"zoom\": 12, \"pitch\": 60, \"bearing\": 30},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "xm06301ewj8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel is responsive\n"
     ]
    }
   ],
   "source": [
    "print(\"Kernel is responsive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "157ec35a-b606-4a6e-91f4-5c073e517e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.char.lower(np.char.strip(classes.astype(str)))\n",
    "\n",
    "m = classes == 'ground'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(elev_vals[m], Viridis_20)\n",
    "\n",
    "m = classes == 'building'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Bilbao_20)\n",
    "\n",
    "m = classes == 'vegetation'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Algae_20)\n",
    "\n",
    "m = classes == 'bridge'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Davos_20)\n",
    "\n",
    "m = classes == 'water'\n",
    "if m.any():\n",
    "    colors_rgb[m] = apply_continuous_cmap(np.full(m.sum(), 0.5), Deep_20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0300e30-0253-43cb-b976-94d9474bd29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground: 2490018\n",
      "building: 446595\n",
      "vegetation: 98\n",
      "bridge: 14660\n",
      "water: 949\n"
     ]
    }
   ],
   "source": [
    "print(\"ground:\", (classes == \"ground\").sum())\n",
    "print(\"building:\", (classes == \"building\").sum())\n",
    "print(\"vegetation:\", (classes == \"vegetation\").sum())\n",
    "print(\"bridge:\", (classes == \"bridge\").sum())\n",
    "print(\"water:\", (classes == \"water\").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gaoj9wppzjw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Connection Error: Can't open a connection to same database file with a different configuration than existing connections\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "DB_PATH = 'duckdb/san_fran_ept_lpc.ddb'\n",
    "try:\n",
    "    con = duckdb.connect(DB_PATH, read_only=True)\n",
    "    con.sql(\"LOAD h3\")\n",
    "    con.sql(\"SELECT COUNT(*) as total_hex FROM san_fran_rich_res_13\").show()\n",
    "    con.sql(\"SELECT dominant_class, COUNT(*) as hex_count FROM san_fran_rich_res_13 GROUP BY 1 ORDER BY 2 DESC\").show()\n",
    "    con.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75065e46-71fe-4f56-9b21-2aeaa4ec608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification + height — per-class sequential colormaps, alpha by density\n",
    "from lonboard import Map, H3HexagonLayer\n",
    "from arro3.core import Table\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from palettable.cmocean.sequential import Algae_20, Deep_20\n",
    "from palettable.scientific.sequential import Bilbao_20, Davos_20\n",
    "from palettable.matplotlib import Viridis_20\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "import pyarrow.compute as pc\n",
    "import duckdb\n",
    "DB_PATH = 'duckdb/san_fran_ept_lpc.ddb'\n",
    "duckdb.sql(\"INSTALL h3 FROM community;\")\n",
    "con = duckdb.connect('duckdb/san_fran_ept_lpc.ddb')\n",
    "con.sql(\"LOAD h3\")\n",
    "df = con.sql(f\"\"\"\n",
    "    SELECT h3_h3_to_string(hex) AS hex, avg_z, ground_z, structure_height, dominant_class, cnt\n",
    "    FROM san_fran_rich_res_13\n",
    "    WHERE cnt > 10\n",
    "\"\"\").fetch_arrow_table()\n",
    "con.close()\n",
    "\n",
    "table = Table.from_arrow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a6c24e7-ee44-498d-b6db-7ffef06c36ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TraitError",
     "evalue": "accessor must have same length as table",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTraitError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     24\u001b[39m     colors_rgb = apply_continuous_cmap(elev_vals[m], Viridis_20)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# # Ground — Viridis by ground_z\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# classes = np.asarray(df.column(\"dominant_class\")).astype(str)\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# classes = np.char.lower(np.char.strip(classes))\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Combine RGB + alpha\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# colors = np.concatenate([colors_rgb, alpha.reshape(-1, 1)], axis=1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m layer = \u001b[43mH3HexagonLayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_hexagon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhex\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_fill_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolors_rgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextruded\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_elevation\u001b[49m\u001b[43m=\u001b[49m\u001b[43melev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43melevation_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstroked\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoverage\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m Map(\n\u001b[32m     77\u001b[39m     layers=[layer],\n\u001b[32m     78\u001b[39m     view_state={\u001b[33m\"\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m\"\u001b[39m: -\u001b[32m122.44\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m37.76\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mzoom\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m12\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpitch\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m60\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbearing\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m30\u001b[39m},\n\u001b[32m     79\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/lonboard/layer/_h3.py:136\u001b[39m, in \u001b[36mH3HexagonLayer.__init__\u001b[39m\u001b[34m(self, table, get_hexagon, _rows_per_chunk, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    119\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    120\u001b[39m     table: ArrowStreamExportable,\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     **kwargs: Unpack[H3HexagonLayerKwargs],\n\u001b[32m    125\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a new H3HexagonLayer.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m \n\u001b[32m    135\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mget_hexagon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_hexagon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_rows_per_chunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_rows_per_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# Assign viewport after get_hexagon has already been validated to be uint64\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# array\u001b[39;00m\n\u001b[32m    145\u001b[39m     default_viewport = default_h3_viewport(\u001b[38;5;28mself\u001b[39m.get_hexagon)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/lonboard/layer/_polygon.py:84\u001b[39m, in \u001b[36mPolygonLayer.__init__\u001b[39m\u001b[34m(self, table, _rows_per_chunk, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     79\u001b[39m     table: ArrowStreamExportable,\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m     **kwargs: Unpack[PolygonLayerKwargs],\n\u001b[32m     83\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_rows_per_chunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_rows_per_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/lonboard/layer/_base.py:410\u001b[39m, in \u001b[36mBaseArrowLayer.__init__\u001b[39m\u001b[34m(self, table, _rows_per_chunk, **kwargs)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28mself\u001b[39m._rows_per_chunk = rows_per_chunk\n\u001b[32m    408\u001b[39m table_o3 = table_o3.rechunk(max_chunksize=rows_per_chunk)\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_o3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/lonboard/layer/_base.py:71\u001b[39m, in \u001b[36mBaseLayer.__init__\u001b[39m\u001b[34m(self, extensions, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     61\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# widgets where the layer is defined. We wish to allow extensions and their\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# properties to be passed in the layer constructor. _However_, if\u001b[39;00m\n\u001b[32m     69\u001b[39m     extension_kwargs = remove_extension_kwargs(extensions, kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;66;03m# Dynamically set layer traits from extensions after calling __init__\u001b[39;00m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mself\u001b[39m._add_extension_traits(extensions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/lonboard/_base.py:25\u001b[39m, in \u001b[36mBaseWidget.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m provided_trait_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_trait_names:\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg.format(provided_trait_name=provided_trait_name))\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:506\u001b[39m, in \u001b[36mWidget.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(**kwargs)\n\u001b[32m    505\u001b[39m Widget._call_widget_constructed(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:525\u001b[39m, in \u001b[36mWidget.open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Open a comm to the frontend if one isn't already open.\"\"\"\u001b[39;00m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.comm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     state, buffer_paths, buffers = _remove_buffers(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    527\u001b[39m     args = \u001b[38;5;28mdict\u001b[39m(target_name=\u001b[33m'\u001b[39m\u001b[33mjupyter.widget\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    528\u001b[39m                 data={\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m: state, \u001b[33m'\u001b[39m\u001b[33mbuffer_paths\u001b[39m\u001b[33m'\u001b[39m: buffer_paths},\n\u001b[32m    529\u001b[39m                 buffers=buffers,\n\u001b[32m    530\u001b[39m                 metadata={\u001b[33m'\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m'\u001b[39m: __protocol_version__}\n\u001b[32m    531\u001b[39m                 )\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:615\u001b[39m, in \u001b[36mWidget.get_state\u001b[39m\u001b[34m(self, key, drop_defaults)\u001b[39m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[32m    614\u001b[39m     to_json = \u001b[38;5;28mself\u001b[39m.trait_metadata(k, \u001b[33m'\u001b[39m\u001b[33mto_json\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m._trait_to_json)\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     value = \u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_defaults \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compare(value, traits[k].default_value):\n\u001b[32m    617\u001b[39m         state[k] = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/lonboard/_serialization.py:135\u001b[39m, in \u001b[36mserialize_accessor\u001b[39m\u001b[34m(data, obj)\u001b[39m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ChunkedArray)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[43mvalidate_accessor_length_matches_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m serialize_pyarrow_column(data, max_chunksize=obj._rows_per_chunk)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/projects/maplibre_copc_lidar/maplibre-gl-usgs-lidar/notebooks/.venv/lib/python3.11/site-packages/lonboard/_serialization.py:159\u001b[39m, in \u001b[36mvalidate_accessor_length_matches_table\u001b[39m\u001b[34m(accessor, table)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_accessor_length_matches_table\u001b[39m(\n\u001b[32m    155\u001b[39m     accessor: Array | ChunkedArray,\n\u001b[32m    156\u001b[39m     table: Table,\n\u001b[32m    157\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accessor) != \u001b[38;5;28mlen\u001b[39m(table):\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TraitError(\u001b[33m\"\u001b[39m\u001b[33maccessor must have same length as table\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTraitError\u001b[39m: accessor must have same length as table"
     ]
    }
   ],
   "source": [
    "\n",
    "n = len(df)\n",
    "avg_z = np.nan_to_num(np.array(pc.fill_null(df[\"avg_z\"], 0)), nan=0)\n",
    "ground_z = np.nan_to_num(np.array(pc.fill_null(df[\"ground_z\"], 0)), nan=0)\n",
    "struct_h = np.clip(np.nan_to_num(np.array(pc.fill_null(df[\"structure_height\"], 0)), nan=0), 0, None)\n",
    "# classes = np.array(df.column(\"dominant_class\"))\n",
    "cnt = np.array(df.column(\"cnt\"))\n",
    "\n",
    "# Extrusion: ground hex by ground_z, structure hex by avg_z\n",
    "elev = pc.if_else(pc.is_valid(classes), ground_z, avg_z)\n",
    "\n",
    "# Normalizers — color ground by ground_z, structures by structure_height\n",
    "norm_elev = Normalize(vmin=np.percentile(ground_z[ground_z > 0], 1) if (ground_z > 0).any() else 0,\n",
    "                      vmax=np.percentile(ground_z[ground_z > 0], 99) if (ground_z > 0).any() else 1, clip=True)\n",
    "# struct_p99 = np.percentile(struct_h[struct_h > 0], 99) if (struct_h > 0).any() else 1\n",
    "# norm_struct = Normalize(vmin=0, vmax=struct_p99, clip=True)\n",
    "\n",
    "elev_vals = norm_elev(ground_z)\n",
    "# struct_vals = norm_struct(struct_h)\n",
    "\n",
    "# apply_continuous_cmap returns RGB (3ch) — build RGB array, add alpha after\n",
    "colors_rgb = np.zeros((n, 3), dtype=np.uint8)\n",
    "m\n",
    "if m.any():\n",
    "    colors_rgb = apply_continuous_cmap(elev_vals[m], Viridis_20)\n",
    "# # Ground — Viridis by ground_z\n",
    "# classes = np.asarray(df.column(\"dominant_class\")).astype(str)\n",
    "# classes = np.char.lower(np.char.strip(classes))\n",
    "\n",
    "\n",
    "# m = classes == 'ground'\n",
    "# if m.any():\n",
    "#     colors_rgb[m] = apply_continuous_cmap(elev_vals[m], Viridis_20)\n",
    "\n",
    "# m = classes == 'building'\n",
    "# if m.any():\n",
    "#     colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Bilbao_20)\n",
    "\n",
    "# m = classes == 'vegetation'\n",
    "# if m.any():\n",
    "#     colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Algae_20)\n",
    "\n",
    "# m = classes == 'bridge'\n",
    "# if m.any():\n",
    "#     colors_rgb[m] = apply_continuous_cmap(struct_vals[m], Davos_20)\n",
    "\n",
    "# m = classes == 'water'\n",
    "# if m.any():\n",
    "#     colors_rgb[m] = apply_continuous_cmap(np.full(m.sum(), 0.5), Deep_20)\n",
    "\n",
    "# colors =\n",
    "# # Alpha by point density — log(cnt) normalized to [80, 255]\n",
    "# log_cnt = np.log1p(cnt.astype(np.float64))\n",
    "# alpha_min, alpha_max = 80, 255\n",
    "# lc_min, lc_max = log_cnt.min(), log_cnt.max()\n",
    "# if lc_max > lc_min:\n",
    "#     alpha = alpha_min + (log_cnt - lc_min) / (lc_max - lc_min) * (alpha_max - alpha_min)\n",
    "# else:\n",
    "#     alpha = np.full(n, alpha_max, dtype=np.float64)\n",
    "# alpha = alpha.astype(np.uint8)\n",
    "\n",
    "# Combine RGB + alpha\n",
    "# colors = np.concatenate([colors_rgb, alpha.reshape(-1, 1)], axis=1)\n",
    "\n",
    "layer = H3HexagonLayer(\n",
    "    table,\n",
    "    get_hexagon=table[\"hex\"],\n",
    "    get_fill_color=colors_rgb,\n",
    "    extruded=True,\n",
    "    get_elevation=elev,\n",
    "    elevation_scale=3,\n",
    "    stroked=False,\n",
    "\n",
    "    coverage=1,\n",
    ")\n",
    "\n",
    "Map(\n",
    "    layers=[layer],\n",
    "    view_state={\"longitude\": -122.44, \"latitude\": 37.76, \"zoom\": 12, \"pitch\": 60, \"bearing\": 30},\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
